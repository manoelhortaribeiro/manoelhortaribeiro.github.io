---
layout: post
title: 'Comments on "A Supply and Demand Framework for YouTube Politics"'
date: 2019-10-07
permalink: /posts/2019/10/comments-supply-and-demand 
name_file: "2019-10-07-Comments-on-A-Supply-and-Demand"

lead: "In this blog post, I will comment on a recent pre-print on YouTube Radicalization, which brought some new and exciting ideas about radicalization on YouTube. The paper is named 'A Supply and Demand Framework for YouTube Politics.'
I believe that the authors have nice arguments in their criticism, but also that the framework they propose has its shortcomings." 

---

---
In this blog post, I will comment on a recent pre-print on YouTube Radicalization, which brought some new and exciting ideas about radicalization on YouTube.
The paper is named ["A Supply and Demand Framework for YouTube Politics."](https://osf.io/73jys/)
I believe that the authors have nice arguments in their criticism, but also that the framework they propose has its shortcomings.
To be fair to them, I think they make it quite clear in the paper that they do not wish their framework to be a "final answer."
In that sense, I believe that this blogpost is what their paper aimed to achieve:
*"to encourage a broader scholarly analysis by pointing out that the algorithm is just one affordance of YouTube "*.
Maybe calling my blog "scholarly analysis" is too much, but I think you got my point.

I would first like to thank the authors for the (working) paper. 
I think it is exciting, I learned a lot about media studies on YouTube that I did not know about, and it just felt like a fresh perspective overall.
The paper brings interesting criticism to what the authors call *The Zombie Bite" Theory of YouTube, 
 which is that:

 > YouTube audiences are at risk of far-right radicalization, and this is because the YouTube algorithm that was designed to  maximize the company's profits via increased audience time  on the platform has learned to show people far-right videos.

The authors then propose a framework, which they name "Supply and Demand," where, according to the authors:

> (...) the novel and disturbing fact of people consuming white nationalist video media was not caused by the supply of this media "radicalizing" an otherwise moderate audience. Rather, the audience already existed, but they were constrained by the scope of the ideology of extant media. The expanded supply allowed them to switch to consuming media more consistent with their ideal points.

I think that Munger and Phillips touch upon a key issue with the narrative they name "*The Zombie Bite Theory*." Namely the idea that *" a model of YouTube media effects that centers the recommendation engine is implausible, an unfortunate update of the hypodermic needle model of media effects that enjoyed some prominence in the 1930s and 1940s but has been consistently discredited ever since "*.
Indeed, I agree this is too simplistic and that the way this is attractive to the media probably makes it easier to pursue this narrative.
Even in our paper, where the findings where much more related to the migration of users than to the algorithm, we consistently got framed as a study about "the algorithm."

I believe that the big issue here is the three mechanisms at play.
The first is radicalization itself, a phenomenon that exists long before recommender systems.
The second is that YouTube favors niche content.
The third is this new factor, the algorithm, which has been pretty hard to study quantitatively.

Interestingly enough, it is hard to tell what is the influence of each of these mechanisms in the surge of fringe content on YouTube:
is it merely a matter of the political times we live in? 
Is it because of how this new media operates? 
Or is the algorithm "infecting" users with its zombie-esque bites?
I don't know.

I have now placed their framework as mostly answering one out of three questions that we face (the one I called the second mechanism).
Yet, my belief that merely their framework is not enough to explain the whole scenario goes slightly beyond this mere intuition.
I believe that their "Supply and Demand" approach cannot explain the phenomena that we have the most evidence about: user migration.
Somehow, YouTube has become fertile ground, not only for the Alt-right but for a pattern of content consumption where users increasingly consume more extreme content.
In that sense, it does not seem that a latent bunch of white supremacists suddenly found the content they strived for, but that they found a place to "draw in" new individuals into their fringe ideas in the platform.

In the paragraphs below, I make some points w.r.t. their quantitative analysis and their comments on our paper.

**Comments about their quantitative analysis:** I see two main shortcomings in their quantitative analysis: 
1) It is unclear if the downfall of videos is due to the significant banning of Alt-right channels on YouTube *and* the migration of such content to other streaming services such as BitChute.
For example, in the Alt-right, the channels ranked 1st, 3rd, 5th in terms of views were banned. It would be interesting if they compared their sample with mine.
2)  Also, they evaluate the search in previous years by tinkering with the search result of the YouTube API.
I think there is no apparent reason to believe that the historical results of today's API reflect the search engine in the past. If there are filters for topics that have attracted polemic videos (such as the ones they searched), it seems pretty likely that these would be in the current API when you search for past videos.

**Comments about comments about our paper:**
Indeed, as the authors have noted, our paper fails to demonstrate that the algorithm has had a noteworthy effect on the audience for Alt-right content.
Yet, this should be understood as a failure to provide positive evidence for the Zombie Bite theory and not as evidence that the algorithm does not work. This is because (and that is stressed in the paper):
1) The algorithm was probably different in previous years, and we only looked in a couple of months of 2019. In fact, Google is allegedly trying to prevent this content from surfacing.
2) We don't have personalization.
Another point worth making here is that they complain about our usage of "Related Channels."
Indeed, it does not play such a big role on YouTube, **but**, here we may find some other cues on how the recommendation system works for the "cold start" case.
While many of the recommendations from the video recommender system point at popular channels (for example, Fox News or CNN), we actually get recommendations that are much more aligned topically.
Indeed, we did not provide this context, and I will probably make this clearer in the next version of the paper.

*Note: In this month still I am drafting another blogpost about some of the criticism and the attention our paper received. 
It has been hard to write much these days as I recently moved!*
